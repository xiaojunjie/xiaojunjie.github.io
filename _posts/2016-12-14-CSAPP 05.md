---
layout: post
title: CSAPP笔记（五） 优化程序性能
categories: note
excerpt: 笔记内容只能保证我看的懂，请不要查看
tags: 计算机
---
[深入理解计算机系统](//csapp.cs.cmu.edu/){:target="csapp"}

## 编译器  

### 局限性  

#### 存储别名的使用  
{% highlight C++ %}
void func1(int *xp, int *yp){
    *xp += *yp;
    *xp += *yp;
}
void func2(int *xp, int *yp){
    *xp += 2**yp;
}
{% endhighlight %}  
如果编译器把func1优化成func2，当xp等于yp时...

#### 函数调用  
{% highlight C++ %}
int f();
int func1() {
    return f() + f() + f() + f();
}
int func2() {
    return 4*f();
}
{% endhighlight %}  
如果编译器敢把func1优化成func2，当f定义如下时...
{% highlight C++ %}
int counter = 0;
int f() {
    return counter++;
}
{% endhighlight %}  
若把f内联到func1中，
{% highlight C++ %}
int counter = 0;
int func1in() {
    int t = counter++;
    t += counter++;
    t += counter++;
    t += counter++;
    return t;
}
{% endhighlight %}  
GCC能优化如下
{% highlight C++ %}
int func1opt() {
    int t = 4 * counter + 6;
    counter = t + 4;
    return t;
}
{% endhighlight %}  

### 程序示例  
待优化的程序
{% highlight C++ %}
 #define IDENT 1
 #define OP *
typedef struct {
    long int len;
    data_t * data;
}vec_rec, * vec_ptr;
vec_ptr new_vec(long int len) {

    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    if (!result)
        return NULL;
    result -> len = len;

    if (len > 0) {
        data_t *data = (data_t*) calloc(len, sizeof(data_t));
        if (!data) {
            free((void*) result);
            return NULL;
        }
        result -> data = data;
    } else
        result -> data = NULL;
    return result;
}
int get_vec_element(vec_ptr v, long int index, data_t* dest) {
    if (index < 0 || index >= v -> len)
        return 0;
        * dest = v -> data[index];
    return 1;
}
long int vec_length(vec_ptr v) {
    return v -> len;
}
void combine1(vec_ptr v, data_t* dest) {
    long int i;
    * est = IDENT;
    for (i = 0; i < vec_length(v); i++) {
        data_t val;
        get_vec_element(v, i, &val);
        * dest = * dest OP val;
    }
}
{% endhighlight %}  
### 代码移动  
- Step 1
{% highlight C++ %}
 #define IDENT 1
 #define OP *
void combine2(vec_ptr v, data_t * dest) {
    long int i;
    long int length = vec_length(v);

    * dest = IDENT;
    for (i = 0; i < length; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        * dest = * dest OP val;
    }

}
{% endhighlight %}  

### 减少调用  
- Step 2
{% highlight C++ %}
 #define IDENT 1
 #define OP *
typedef struct {
    long int len;
    data_t * data;
}vec_rec, * vec_ptr;
data_t * get_vec_start(vec_ptr v){
    return v->data;
}
void combine3(vec_ptr v, data_t * dest) {
    long int i;
    long int length = vec_length(v);
    //直接定位到数据结构的主体区
    data_t * data = get_vec_start(v);
    * dest = IDENT;
    for (i = 0; i < length; i++) {
        //基于前面的定位去访问元素
        * dest = * dest OP data[i];
    }
}
{% endhighlight %}  
当把编译器的优化等级调到2时会发现，下面注释的movss被优化掉了，  
也就是for中的第个dest并没有访存，而是直接用上次循环的结果，也就是第21行的。
{% highlight Python %}
 # gcc -S combine.cpp -O2
 # for循环的汇编代码
 17 .L2:
          # movss   (%rsi), %xmm0
 18         mulss   (%rdi), %xmm0
 19         addq    $4, %rdi
 20         cmpq    %rax, %rdi
 21         movss   %xmm0, (%rsi)
 22         jne     .L2
 23         rep ret
 {% endhighlight %}
[存储别名的使用](#存储别名的使用)是指编译器不知两个别名是否指向同一地址，而这里肯定是同一地址。

### 减少访存  
- Step 3
{% highlight C++ %}
 #define IDENT 1
 #define OP *
void combine4(vec_ptr v, data_t * dest){
    long int i;
    long int length = vec_length(v);
    data_t * data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; i++) {
        acc = acc OP data[i];
    }
    * dest = acc;
}
{% endhighlight %}
由于[存储别名的使用](#存储别名的使用)，编译器并不会把[combine3](#减少调用)优化成[combine4](#减少访存)，  
因为[combine3](#减少调用)中的dest是完全有可能指向data[i]，也就是说v累乘的结果可能保存在v的某个元素中  
如果错误地优化了...  

## 处理器

### 整体框图
![处理器]({{ site.storage }}/assets/dist/img/2016-12-15 14-43-33屏幕截图.png)  

- 退役单元(Retirement Unit): 记录正在的执行的指令  
指令译码后会传送到退役单元的队列中，等待分支预测赤决定是否写寄存器文件  
[PIPE](/note/CSAPP-04/#执行14){:target="PIPE"}中E是根据e_con和icode传送信息到D  

- 操作结果(Operation results): 指令间转发数据
  寄存器重命名(register renaming)**译码** 时，某指令要更新寄存器r，则产生（r,t）标记入表(renaming table)。  
  后续指令要调用r时会在译码时带上t作为源操作数(operand value)进入执行单元。  
  前指令得出结果v，带t指令会直接引用v  
  [PIPE](/note/CSAPP-04/##译码和写回){:target="PIPE"}中是在译码时被动等待前指令传回数值，不回传就卡在那里不走了  
  而这里是在执行阶段是主动调用  

### 抽象模型  
![延迟]({{ site.storage }}/assets/dist/img/2016-12-16 20-44-45屏幕截图.png)  
延迟(Latency)：执行一条指令所需周期  
发射(Issue)： 两条指令间间隔  
发射为1说明，说明每个周期都执行一条指令，完全流水线化  
加法0.33是因为硬件上有3个加法运算单元  
{% highlight C++ %}
for (i = 0; i < length; i++) {
    acc = acc * data[i];
}

.L488:
    mulss (%rax,%rdx,4), %xmm0
    addq $1, %rdx   //i++
    cmpq %rdx, %rbp  //i < length
    jg .L488
{% endhighlight %}
![数据流图]({{ site.storage }}/assets/dist/img/2016-12-16 20-03-36屏幕截图.png)  
在一个循环中，乘和加数据不相关，乘和加的指令流水可近似看成乘和加并行  
![数据流图]({{ site.storage }}/assets/dist/img/2016-12-16 20-17-48屏幕截图.png)  
跳转指令不影响数据流，忽略不计。[关键路径](//zh.wikipedia.org/zh-hans/关键路径){:target="wikipedia"}在于乘法运算  
{% highlight C++ %}
f(x)是关于x的degree次多项式，a是各项系数，poly求f(x)
double poly(double a[], double x, int degree){
    long int i;
    double result = a[0];
    double xpwr = x;
    for (i = 1; i <= degree; i++) {
        result += a[i] * xpwr;
        xpwr = x * xpwr;
    }
    return result;
}
{% endhighlight %}
如果仿照上面画出流程图，显然三条主线  
1 result -> result  
2 xpwr -> xpwr  
3 临时寄存器 -> 临时寄存器  
其中临时寄存器存放 a[i]* xpwr 的结果  
两个乘法数据不相关，但result+却依赖乘法结果。  
其实result+完全可以推迟到下个循环，如下：
{% highlight C++ %}
r=0
for{
    result += r;
    r = a[i] * xpwr;
    xpwr = x * xpwr;
}
result += r;
{% endhighlight %}
3条主线中，第二个乘法为关键路径，时间(5)最紧，加法时间(3)最松，也就是说乘法是不停运算，而加法有两个周期休息，  
第一个乘法其实是打酱油的，虽然时间也是5，完全可以视其为常数，因为它是跟着第二个乘法顺便算下  
{% highlight C++ %}
for{
    result += 1.0;
    xpwr = x * xpwr;
}
{% endhighlight %}    

再看一代码

{% highlight C++ %}
 # 同样求f(x)，用Horner法迭代分离x
 # a0 + x(a1 + x·a2))
double polyh(double a[], double x, int degree){
    long int i;
    double result = a[degree];
    for (i = degree-1; i >= 0; i--)
    result = a[i] + x*result;
    return result;
}
{% endhighlight %}
这种运算无解，result->result是没法等到下轮循环再计算  
时间（5+3）  
由此可以，减少运算并不一定会提高性能，降低运算的相关性也很重要  

## 程序变换  

### 循环展开  
只提高了整数运算性能
{% highlight C++ %}
 #combine5
//2次展开
for (i = 0; i < length/2; i+=2) {
    acc = (acc OP data[i]) OP data[i+1];
}
//扫尾
for{}
{% endhighlight %}
OP对应的延时如下  
![循环展开]({{ site.storage }}/assets/dist/img/2016-12-17 19-19-54屏幕截图.png)  
发现循环展开对浮点数运算没有有效果。看下图，浮点数运算的关键路径在于左侧  
每轮OP运算必须等到上轮所有OP结束才能开始，这样就成串行了。  
但整数运算性能居然提高了，这是因为GCC的优化，[后面](#结合变换)会解释  
![浮点循环展开]({{ site.storage }}/assets/dist/img/2016-12-17 19-22-17屏幕截图.png)  

### 多路并行  
整数和浮点都提高了
{% highlight C++ %}
 #combine6
for (i = 0; i < length/2; i+=2) {
    acc0 = acc0 OP data[i];
    acc1 = acc1 OP data[i+1];
}
{% endhighlight %}
![多路并行]({{ site.storage }}/assets/dist/img/2016-12-17 13-30-30屏幕截图.png)  
补码乘加是有结合性的，但是浮点因为溢出的问题就没有结合性，但并行计算的准确性并不一定比顺序计算的差，这个不好说。更多情况下，运算性能更重要。

### 结合变换  
整数和浮点都提高了
{% highlight C++ %}
 #combine7
for (i = 0; i < length/2; i+=2) {
    acc = acc OP (data[i] OP data[i+1]);
}
{% endhighlight %}
![结合变换]({{ site.storage }}/assets/dist/img/2016-12-17 16-14-25屏幕截图.png)  
类似前面的poly函数，把第一个OP推迟到下个循环，也就是每个循环计算的是上次循环的op1和本次的op2。  
上面是2次结合变换，如果是3次结合变换，第一个OP推迟到下下个循环，每次循环是3个乘法并行。  
combine7性能与[combine6](#结合变换)差不多，与[combine5](#循环展开)对比，只移动了个括号，浮点运算的性能翻倍。
而[combine5](#循环展开)浮点运算性能差的关键原因在于两个OP都需要acc参与计算，也就是说第二轮循环一定要等到第一轮中OP **全部** 运算结束才能开始，而combine7没有这么严格限制。  
但[combine5](#循环展开)中整数运算性能提高了，这是因为GCC把整数运算的优化成combine7形式，  
而浮点数运算没有结合性，GCC不敢优化，所以combine7这里需要程序员手动对浮点数进行结合变换。  
{% highlight C++ %}
//r,x,y,z均为浮点数，浮点乘法延迟为5
r = ( (rx) y )z; // 3/3*5  与r相关的运算占3/3
r = ( r(xy) )z;  // 2/3*5
r = r( (xy)z );  // 1/3*5
r = r( x(yz) );  // 1/3*5
r = (rx) (yz);   // 2/3*5
...
{% endhighlight %}

### 分支预测  
{% highlight C++ %}
void merge(int src1[], int src2[], int dest[], int n) {
    int i1 = 0;
    int i2 = 0;
    int id = 0;
    while (i1 < n && i2 < n) {
        if (src1[i1] < src2[i2])
            dest[id++] = src1[i1++];
        else
            dest[id++] = src2[i2++];
    }
    while (i1 < n)
        dest[id++] = src1[i1++];
    while (i2 < n)
        dest[id++] = src2[i2++];
}
{% endhighlight %}  
三个while都只会错一次，而if不好说，第一个while汇编如下，入口.L2  
{% highlight Python %}
.L8:
	movl	28(%esp), %ebx
	addl	$1, %eax # i1++
	movl	%edi, -4(%ebx,%ecx,4) # src1[i1]->dest[id]
.L5:
	addl	$1, %ecx # id++
.L2:
	cmpl	%esi, %eax  # n <= i1
	jge	.L1
	cmpl	%esi, %edx  # n <= i2
	jge	.L1
	movl	24(%esp), %ebx
	movl	0(%ebp,%eax,4), %edi # src1[i1]
	movl	(%ebx,%edx,4), %ebx  # src2[i2]
	cmpl	%ebx, %edi # 2 > 1
	jl	.L8
	movl	28(%esp), %edi # dest
	addl	$1, %edx  # i2++
	movl	%ebx, -4(%edi,%ecx,4) # src2[i2]->dest[id]
	jmp	.L5
{% endhighlight %}
改成条件转移
{% highlight C++ %}
int v1 = src1[i1];
int v2 = src2[i2];
int taken = v1 < v2;
dest[id++] = taken ? v1:v2;
i1 += taken;
i2 += 1-taken;
{% endhighlight %}
{% highlight Python %}
.L9:
	cmpl	%ebx, 32(%esp)
	jle	.L5
.L6:
	movl	(%edi,%ebx,4), %eax # 1->
	xorl	%edx, %edx
	cmpl	%eax, 0(%ebp,%ecx,4) # 左1右2
	cmovle	0(%ebp,%ecx,4), %eax # 右>=左时mov
	setl	%dl # 左<右时dl为1
	addl	$4, %esi
	movl	%eax, -4(%esi)
	movl	$1, %eax
	addl	%edx, %ecx # 2
	subl	%edx, %eax # (1-taken)
	addl	%eax, %ebx # 1
	cmpl	%ecx, 32(%esp)
	jg	.L9
.L5:
    # 剩下的两个while
{% endhighlight %}
jg和jle是while (i1 < n && i2 < n)逻辑，[前后向分支](/note/csapp-4.54/#前(后)向分支)，谁的地址小就先执行谁，L5最大，故只会猜错一次。初看感觉很奇怪，为啥要把两个分支预测一个头一个尾。如果都放头，尾部要多个jmp跳头；如果都放尾部，"&&"逻辑比较麻烦，如果while中是“或”逻辑就比较好搞。

## 存储器  
![存储与加载]({{ site.storage }}/assets/dist/img/2016-12-20 15-34-41屏幕截图.png)  
Load前会先检查Store buffer，有则取之。
{% highlight C++ %}
void psum1(float a[], float p[], long int n){
    long int i;
    p[0] = a[0];
    for (i = 1; i < n; i++)
        p[i] = p[i-1] + a[i];
}
{% endhighlight %}
如果不考虑编译器优化，存储与加载数据相关，需要在存储的同时也保存到寄存器中，变动如下。  
实际gcc -O3也能达到此效果。
{% highlight C++ %}
temp = p[0]=a[0];
for (int i = 0; i < n; i++) {
    int val  = temp+a[i-1];
    p[i] = val;
    temp = val;
}
{% endhighlight %}
